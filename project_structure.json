{
    "project_structure": [
        "CircleTool.py",
        "CopyObjects.py",
        "Exit.py",
        "ExtractObjects.py",
        "GUI.py",
        "Main.py",
        "scripts.py",
        "SelectObjects.py",
        "Undo.py",
        "model\\u2net.py"
    ],
    "code_files": {
        "CircleTool.py": {
            "methods": [
                "process_circle_area",
                "select_circle_tool",
                "continuously_process_circle_area",
                "draw_cursor_circle",
                "on_circle_paint",
                "on_circle_paint_release",
                "on_circle_paint_right",
                "on_circle_paint_right_motion",
                "update_circle_radius",
                "update_gap_filling_level",
                "repeat_processing"
            ],
            "code": "import cv2\nimport numpy as np\nfrom skimage.morphology import skeletonize\nimport time\nimport threading\nfrom tkinter import ttk\n\n# Process a circular area of the image\ndef process_circle_area(x, y, open_cv_image, edge_mask, contours, circle_radius, gap_filling_level, handle_contour_coloring, history, update_canvas, remove_edges=False):\n    # Define the circular region of interest\n    mask = np.zeros(open_cv_image.shape[:2], dtype=np.uint8)\n    cv2.circle(mask, (x, y), circle_radius - 4, 255, -1)\n    \n    # Extract the region below the circle\n    region_edges = cv2.bitwise_and(edge_mask, mask) if edge_mask is not None else None\n    if region_edges is None or not np.any(region_edges):\n        # If there are no edges in the selected region, do nothing\n        return edge_mask, contours\n    \n    # Apply morphological dilation to bridge gaps within the selected region using a cross-shaped kernel\n    kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (3, 3))  # Cross-shaped kernel for better control of growth direction\n    dilated_edges = cv2.dilate(region_edges, kernel, iterations=gap_filling_level)\n    \n    # Use active contour refinement\n    # Skeletonize the region to refine the edges\n    skeleton = skeletonize(dilated_edges > 0).astype(np.uint8) * 255\n    \n    if remove_edges:\n        # Remove edges within the circular region\n        edge_mask = cv2.bitwise_and(edge_mask, cv2.bitwise_not(mask)) if edge_mask is not None else None\n    else:\n        # Update edge mask with processed edges\n        edge_mask = cv2.bitwise_or(edge_mask, skeleton) if edge_mask is not None else skeleton\n    \n    # Update contours after processing or removal\n    contours, _ = cv2.findContours(edge_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    \n    # Update the display with the newly processed area\n    updated_image = handle_contour_coloring(open_cv_image.copy(), [], contours)\n    \n    # Save the state to history\n    history.append(updated_image.copy())\n    \n    # Update the canvas\n    update_canvas(updated_image)\n    \n    return edge_mask, contours\n\n# Tool selection for circular processing\ndef select_circle_tool(canvas, root, draw_cursor_circle, size_slider_frame, gap_filling_slider_frame, on_circle_paint, continuously_process_circle_area, on_circle_paint_release, on_circle_paint_right, on_circle_paint_right_motion):\n    tool_mode = \"circle\"\n    canvas.config(cursor=\"none\")  # Hide the default cursor\n    size_slider_frame.pack(side=\"right\", fill=\"y\")\n    gap_filling_slider_frame.pack(side=\"right\", fill=\"y\")\n    canvas.unbind(\"<Motion>\")\n    root.bind(\"<Motion>\", draw_cursor_circle)  # Enable red circle cursor\n    canvas.unbind(\"<ButtonPress-1>\")\n    canvas.unbind(\"<B1-Motion>\")\n    canvas.unbind(\"<ButtonRelease-1>\")\n    canvas.bind(\"<ButtonPress-1>\", on_circle_paint)\n    canvas.bind(\"<B1-Motion>\", continuously_process_circle_area)\n    canvas.bind(\"<ButtonRelease-1>\", on_circle_paint_release)\n    canvas.bind(\"<ButtonPress-3>\", on_circle_paint_right)\n    canvas.bind(\"<B3-Motion>\", on_circle_paint_right_motion)\n\n# Continuously process a circular area\ndef continuously_process_circle_area(event, process_circle_area, mouse_pressed):\n    x, y = event.x, event.y\n    def repeat_processing():\n        while mouse_pressed:\n            process_circle_area(x, y)\n            time.sleep(0.5)  # Repeat every 0.5 seconds\n    threading.Thread(target=repeat_processing, daemon=True).start()\n\n# Draw the initial cursor circle only if the tool is selected\ndef draw_cursor_circle(event, canvas, tool_mode, circle_radius):\n    if tool_mode == \"circle\":  # Only draw if the circle tool is active\n        canvas.delete(\"cursor_circle\")\n        canvas.create_oval(event.x - circle_radius, event.y - circle_radius, event.x + circle_radius, event.y + circle_radius, outline=\"red\", width=2, tags=\"cursor_circle\")\n\n# Handle circle paint\nmouse_pressed = False\n\ndef on_circle_paint(event):\n    global mouse_pressed\n    mouse_pressed = True\n    process_circle_area(event.x, event.y)\n    continuously_process_circle_area(event)\n\ndef on_circle_paint_release(event):\n    global mouse_pressed\n    mouse_pressed = False\n\ndef on_circle_paint_right(event):\n    process_circle_area(event.x, event.y, remove_edges=True)\n\ndef on_circle_paint_right_motion(event):\n    process_circle_area(event.x, event.y, remove_edges=True)\n\n# Add sliders for circle size and gap filling level\ndef update_circle_radius(value, circle_radius, size_slider_value):\n    circle_radius = int(float(value))\n    size_slider_value.config(text=str(circle_radius))\n\ndef update_gap_filling_level(value, gap_filling_level, gap_filling_slider_value):\n    gap_filling_level = int(float(value))\n    gap_filling_slider_value.config(text=str(gap_filling_level))\n"
        },
        "CopyObjects.py": {
            "methods": [
                "copy_objects",
                "update_copy_button_state"
            ],
            "code": "import cv2\nimport numpy as np\nimport io\nimport win32clipboard\nfrom PIL import Image as PilImage\n\n# Copy selected objects to clipboard\ndef copy_objects(open_cv_image, selected_objects):\n    if not selected_objects:\n        return\n    # Create an empty transparent image\n    copied_image = np.zeros((open_cv_image.shape[0], open_cv_image.shape[1], 4), dtype=np.uint8)\n    for contour in selected_objects:\n        mask = np.zeros_like(open_cv_image[:, :, 0], dtype=np.uint8)\n        cv2.drawContours(mask, [contour], -1, 255, -1)\n        # Copy RGB channels from the original image\n        for c in range(3):\n            copied_image[:, :, c] = cv2.bitwise_and(open_cv_image[:, :, c], open_cv_image[:, :, c], mask=mask)\n        # Set alpha channel based on mask\n        copied_image[:, :, 3] = mask\n    output = PilImage.fromarray(copied_image, 'RGBA')\n    output_buffer = io.BytesIO()\n    output.save(output_buffer, format='BMP')\n    data = output_buffer.getvalue()[14:]\n    output_buffer.close()\n\n    # Set the image to clipboard\n    win32clipboard.OpenClipboard()\n    win32clipboard.EmptyClipboard()\n    win32clipboard.SetClipboardData(win32clipboard.CF_DIB, data)\n    win32clipboard.CloseClipboard()\n\n# Update copy button state\ndef update_copy_button_state(selected_objects, copy_button):\n    if selected_objects:\n        copy_button.config(state=\"normal\")\n    else:\n        copy_button.config(state=\"disabled\")\n"
        },
        "Exit.py": {
            "methods": [
                "exit_application"
            ],
            "code": "# Exit application\ndef exit_application(root):\n    root.quit()\n    root.destroy()\n    import os\n    os._exit(0)  # Forcefully terminate the program\n"
        },
        "ExtractObjects.py": {
            "methods": [
                "extract_objects"
            ],
            "code": "import cv2\nimport numpy as np\n\n# Extract objects from the image\ndef extract_objects(open_cv_image, handle_contour_coloring, history, update_canvas):\n    edge_mask, contours = None, []\n    print(\"Extract Objects button clicked\")\n    \n    # Step 1: Bilateral Filter + Gaussian Blur + Edge Detection (Canny) + Thresholding\n    bilateral_filtered = cv2.bilateralFilter(open_cv_image, 9, 75, 75)  # Preserve edges while reducing noise\n    blurred = cv2.GaussianBlur(bilateral_filtered, (5, 5), 0)\n    edges = cv2.Canny(blurred, 30, 100)  # Adjusted thresholds for better edge detection\n    \n    # Store the edge mask for later use in selecting objects\n    edge_mask = edges\n    \n    # Find contours from the edge mask\n    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    \n    # Create an edge overlay on the original image\n    edge_highlight = handle_contour_coloring(open_cv_image.copy(), [], contours)\n    \n    # Save the state to history\n    history.append(edge_highlight.copy())\n    \n    # Update the canvas with the highlighted image\n    update_canvas(edge_highlight)\n\n    return edge_mask, contours\n"
        },
        "GUI.py": {
            "methods": [
                "capture_selected_area",
                "handle_contour_coloring",
                "update_canvas"
            ],
            "code": "import tkinter as tk\nfrom tkinter import ttk\nfrom PIL import Image, ImageTk, ImageGrab\nimport cv2\nimport numpy as np\n\n# Capture selected area and show image in GUI\ndef capture_selected_area(x1, y1, x2, y2, history, update_canvas, handle_contour_coloring):\n    # Ensure the coordinates are in the correct order\n    x1, x2 = min(x1, x2), max(x1, x2)\n    y1, y2 = min(y1, y2), max(y1, y2)\n    \n    # Grab the selected screen area\n    image = ImageGrab.grab(bbox=(x1, y1, x2, y2)).convert(\"RGBA\")\n    \n    # Convert the image to an OpenCV format\n    open_cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGBA2BGR)\n    \n    # Initialize the GUI\n    root = tk.Tk()\n    root.title(\"Snipped Image Viewer\")\n    \n    # Set up main frame with a vertical panel on the left\n    main_frame = tk.Frame(root)\n    main_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n\n    tools_panel = tk.Frame(main_frame, width=100, bg=\"lightgrey\")\n    tools_panel.pack(side=tk.LEFT, fill=tk.Y)\n\n    # Set up canvas to display the image\n    canvas = tk.Canvas(main_frame, width=image.width, height=image.height, scrollregion=(0, 0, image.width, image.height))\n    hbar = tk.Scrollbar(main_frame, orient=tk.HORIZONTAL, command=canvas.xview)\n    hbar.pack(side=tk.BOTTOM, fill=tk.X)\n    vbar = tk.Scrollbar(main_frame, orient=tk.VERTICAL, command=canvas.yview)\n    vbar.pack(side=tk.RIGHT, fill=tk.Y)\n    canvas.config(xscrollcommand=hbar.set, yscrollcommand=vbar.set)\n    canvas.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True)\n    \n    # Display the captured image\n    photo = ImageTk.PhotoImage(image)\n    canvas_image_id = canvas.create_image(0, 0, anchor=\"nw\", image=photo)\n    canvas.image = photo\n    \n    # Save the initial state to history for undo functionality\n    history.append(open_cv_image.copy())\n\n    # Function to update the canvas image\n    def update_canvas(updated_image):\n        highlighted_pil = Image.fromarray(cv2.cvtColor(updated_image, cv2.COLOR_BGR2RGB))\n        highlighted_photo = ImageTk.PhotoImage(highlighted_pil)\n        canvas.itemconfig(canvas_image_id, image=highlighted_photo)\n        canvas.image = highlighted_photo\n\n    return root, canvas, tools_panel, open_cv_image, canvas_image_id\n\n# Handle contour coloring and selection\ndef handle_contour_coloring(updated_image, selected_contours, all_contours):\n    overlay = updated_image.copy()\n    # Draw selected contours first with blue color\n    for contour in selected_contours:\n        color = (173, 216, 230)  # Baby blue for selected objects\n        cv2.drawContours(overlay, [contour], -1, color, 2)\n        if cv2.contourArea(contour) > 100:\n            overlay_contour = overlay.copy()\n            cv2.drawContours(overlay_contour, [contour], -1, color, thickness=cv2.FILLED)\n            alpha = 0.4  # Higher alpha for selected contours\n            cv2.addWeighted(overlay_contour, alpha, overlay, 1 - alpha, 0, overlay)\n    # Draw non-selected contours with green color\n    for contour in all_contours:\n        if not any(np.array_equal(contour, selected) for selected in selected_contours):\n            color = (0, 255, 0)  # Green for non-selected objects\n            cv2.drawContours(overlay, [contour], -1, color, 2)\n            if cv2.contourArea(contour) > 100:\n                overlay_contour = overlay.copy()\n                cv2.drawContours(overlay_contour, [contour], -1, color, thickness=cv2.FILLED)\n                alpha = 0.2  # Lower alpha for non-selected contours\n                cv2.addWeighted(overlay_contour, alpha, overlay, 1 - alpha, 0, overlay)\n    return overlay\n"
        },
        "Main.py": {
            "methods": [
                "update_canvas",
                "select_area",
                "run_tray",
                "on_mouse_down",
                "on_mouse_drag",
                "on_mouse_up"
            ],
            "code": "import threading\nimport keyboard\nfrom pystray import MenuItem as item\nfrom PIL import Image as PilImage\nimport pystray\nimport time\nimport os\nfrom GUI import capture_selected_area, handle_contour_coloring\nfrom Undo import undo_last_action\nfrom CopyObjects import copy_objects, update_copy_button_state\nfrom CircleTool import process_circle_area, select_circle_tool, draw_cursor_circle, on_circle_paint, continuously_process_circle_area, on_circle_paint_release, on_circle_paint_right, on_circle_paint_right_motion, update_circle_radius, update_gap_filling_level\nfrom SelectObjects import select_objects, update_selected_objects\nfrom Exit import exit_application\nimport tkinter as tk\nfrom tkinter import ttk\nimport cv2\nimport numpy as np\nfrom PIL import Image, ImageTk\n\n# Function to update the canvas image\ndef update_canvas(updated_image, canvas_image_id):\n    highlighted_pil = Image.fromarray(cv2.cvtColor(updated_image, cv2.COLOR_BGR2RGB))\n    highlighted_photo = ImageTk.PhotoImage(highlighted_pil)\n    canvas.itemconfig(canvas_image_id, image=highlighted_photo)\n    canvas.image = highlighted_photo\n\n# Select area on the screen\ndef select_area():\n    root = tk.Tk()\n    root.attributes(\"-fullscreen\", True)\n    root.attributes(\"-alpha\", 0.3)\n    root.config(bg=\"black\")\n    root.after(10, lambda: root.focus_force())  # Bring the window to the foreground after a short delay\n    start_x = start_y = end_x = end_y = 0\n    rect = None\n\n    def on_mouse_down(event):\n        nonlocal start_x, start_y, rect\n        start_x = event.x_root\n        start_y = event.y_root\n        if rect:\n            canvas.delete(rect)\n        rect = canvas.create_rectangle(start_x, start_y, start_x, start_y, outline=\"red\", width=2)\n\n    def on_mouse_drag(event):\n        nonlocal rect, end_x, end_y\n        end_x = event.x_root\n        end_y = event.y_root\n        if rect:\n            canvas.delete(rect)\n        rect = canvas.create_rectangle(start_x, start_y, end_x, end_y, outline=\"red\", width=2)\n\n    def on_mouse_up(event):\n        root.quit()\n        root.destroy()\n        history = []  # Initialize history\n        root_viewer, canvas_viewer, tools_panel, open_cv_image, canvas_image_id = capture_selected_area(start_x, start_y, end_x, end_y, history, update_canvas, handle_contour_coloring)\n        root_viewer.mainloop()\n\n    canvas = tk.Canvas(root, cursor=\"cross\")\n    canvas.pack(fill=\"both\", expand=True)\n    canvas.bind(\"<ButtonPress-1>\", on_mouse_down)\n    canvas.bind(\"<B1-Motion>\", on_mouse_drag)\n    canvas.bind(\"<ButtonRelease-1>\", on_mouse_up)\n    root.mainloop()\n\n# Tray icon setup\ndef run_tray():\n    icon_image = PilImage.open(\"icon.ico\")\n    icon = pystray.Icon(\"NoBackgroundSnipper\", icon_image, menu=pystray.Menu(item('Exit', exit_application)))\n    icon.run()\n\n# Start tray and set up hotkeys\nif __name__ == \"__main__\":\n    tray_thread = threading.Thread(target=run_tray, daemon=True)\n    tray_thread.start()\n    time.sleep(1)  # Wait for the tray icon to initialize properly\n    keyboard.add_hotkey(\"ctrl+alt+s\", select_area)\n    keyboard.add_hotkey(\"ctrl+alt+q\", lambda: os._exit(0))  # Forcefully terminate the program\n    print(\"Running in the system tray. Press Ctrl+Alt+S to capture screen selection. Press Ctrl+Alt+Q to exit.\")\n    keyboard.wait(\"esc\")\n"
        },
        "scripts.py": {
            "methods": [
                "advanced_background_removal",
                "pre_render_images",
                "show_tuning_interface",
                "capture_selected_area",
                "select_area",
                "on_exit",
                "run_tray",
                "render_batch",
                "__init__",
                "on_slider_change",
                "show_prev_image",
                "show_next_image",
                "update_image",
                "on_mouse_down",
                "on_mouse_drag",
                "on_mouse_up"
            ],
            "code": "import concurrent.futures\nimport threading\nimport time\nimport tkinter as tk\nfrom tkinter import ttk\nfrom PIL import Image, ImageTk, ImageGrab, ImageFilter\nimport numpy as np\nimport cv2\nfrom queue import LifoQueue\nimport keyboard\nimport pystray\nfrom pystray import MenuItem as item\nfrom io import BytesIO\nimport win32clipboard\nfrom PIL import Image as PilImage  # For icon loading\nimport sys\n\n# Define constants and global variables\nDEFAULT_THRESHOLD = 100\nINITIAL_THRESHOLD_RANGE = 30\nRENDER_QUEUE = LifoQueue()  # Stack to store pre-rendered images\nprocessed_images = {}  # Cache of processed images by threshold value\nprogress_count = 0  # Global counter for tracking progress\n\n# Practical ranges for parameter combinations (simplified for performance)\nthreshold_values = list(range(50, 151, 10))\nblur_values = [1, 2, 3]\nedge_low_values = [20, 40, 60]\nedge_high_values = [100, 120, 140]\nmorph_iterations = [1, 2]\ngrabcut_iterations = [2, 3]\ntotal_combinations = len(threshold_values) * len(blur_values) * len(edge_low_values) * len(edge_high_values) * len(morph_iterations) * len(grabcut_iterations)\n\n# Initial pre-rendering batch centered around the default threshold\ninitial_batch = [(th, blur_values[0], edge_low_values[0], edge_high_values[0], morph_iterations[0], grabcut_iterations[0])\n                 for th in range(DEFAULT_THRESHOLD - INITIAL_THRESHOLD_RANGE,\n                                 DEFAULT_THRESHOLD + INITIAL_THRESHOLD_RANGE + 1, 10)]\n\n# Full combinations for background pre-rendering after the GUI is shown\ncombinations = [(th, bl, el, eh, mi, gi) for th in threshold_values for bl in blur_values \n                for el in edge_low_values for eh in edge_high_values \n                for mi in morph_iterations for gi in grabcut_iterations]\n\n# Advanced background removal function\ndef advanced_background_removal(input_image, threshold, canny_threshold1, canny_threshold2, grabcut_iter):\n    image = cv2.cvtColor(np.array(input_image), cv2.COLOR_RGBA2BGRA)\n    \n    # Ensure the image is in 3-channel BGR format for grabCut\n    if image.shape[2] == 4:  # Check if the image has an alpha channel\n        image = cv2.cvtColor(image, cv2.COLOR_BGRA2BGR)\n\n    original_image = image.copy()\n\n    # Step 1: Gaussian Blur for Noise Reduction\n    blurred = cv2.GaussianBlur(image, (3, 3), 0)\n\n    # Step 2: Convert to HSV and apply Color Segmentation for mask creation\n    hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)\n    lower_bound = np.array([0, 0, threshold])  # Adjust based on slider input\n    upper_bound = np.array([180, 255, 255])\n    mask_hsv = cv2.inRange(hsv, lower_bound, upper_bound)\n\n    # Step 3: Edge Detection using Canny with adjustable thresholds\n    edges = cv2.Canny(blurred, canny_threshold1, canny_threshold2)\n    _, mask_edges = cv2.threshold(edges, 1, 255, cv2.THRESH_BINARY)\n\n    # Combine HSV and Edge-based masks for a refined mask\n    combined_mask = cv2.bitwise_or(mask_hsv, mask_edges)\n\n    # Step 4: Morphological Operations to refine the mask\n    kernel = np.ones((3, 3), np.uint8)\n    combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, kernel, iterations=3)\n    combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_OPEN, kernel, iterations=2)\n\n    # Step 5: GrabCut refinement\n    mask_grabcut = np.zeros(image.shape[:2], np.uint8)\n    bg_model = np.zeros((1, 65), np.float64)\n    fg_model = np.zeros((1, 65), np.float64)\n    rect = (5, 5, image.shape[1] - 10, image.shape[0] - 10)\n    cv2.grabCut(original_image, mask_grabcut, rect, bg_model, fg_model, grabcut_iter, cv2.GC_INIT_WITH_RECT)\n    mask_grabcut = np.where((mask_grabcut == 2) | (mask_grabcut == 0), 0, 1).astype(\"uint8\")\n    result = original_image * mask_grabcut[:, :, np.newaxis]\n\n    # Convert result to RGBA with transparency where background is removed\n    result_rgba = cv2.cvtColor(result, cv2.COLOR_BGR2BGRA)\n    result_rgba[:, :, 3] = (mask_grabcut * 255)  # Set alpha channel based on mask\n\n    return PilImage.fromarray(result_rgba, \"RGBA\")\n\n# Pre-render images for each combination\n# Pre-render images for each combination\n# Pre-render images for each combination\ndef pre_render_images(image, batch, all_combinations, progress_label, tuner_app):\n    global progress_count\n    progress_count = 0  # Initialize progress_count to zero\n\n    def render_batch(batch, initial_display=False):\n        global progress_count\n        for params in batch:\n            print(f\"Rendering with parameters: {params}\")\n            processed_image = advanced_background_removal(image, *params[:4])\n            processed_images[params[0]] = processed_image\n            RENDER_QUEUE.put((params[0], processed_image))\n            progress_count += 1\n\n            # Update the progress label\n            progress_label.config(text=f\"Rendering Progress: {progress_count}/{total_combinations}\")\n            progress_label.update_idletasks()  # Ensure the label updates immediately\n\n            # Display the first rendered image immediately\n            if initial_display and progress_count == 1:\n                tuner_app.update_image(params[0])\n\n    # Render the initial batch and show the first image\n    print(\"Starting initial batch rendering...\")\n    render_batch(batch, initial_display=True)\n    print(\"Initial batch rendering completed.\")\n\n    # Continue rendering remaining combinations in the background\n    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n        executor.map(lambda params: render_batch([params]), all_combinations)\n\n# Tuning GUI with slider and progress label\nclass BackgroundRemovalTuner:\n    def __init__(self, root, image, progress_label):\n        self.root = root\n        self.image = image\n        self.progress_label = progress_label  # Set the progress label\n\n        # Set up GUI elements\n        self.canvas = tk.Canvas(root, width=image.width, height=image.height)\n        self.canvas.pack()\n        \n        # Slider for threshold adjustment\n        self.threshold_slider = ttk.Scale(root, from_=DEFAULT_THRESHOLD - INITIAL_THRESHOLD_RANGE,\n                                          to=DEFAULT_THRESHOLD + INITIAL_THRESHOLD_RANGE,\n                                          orient=\"horizontal\", command=self.on_slider_change)\n        self.threshold_slider.pack()\n\n        # Previous and Next buttons\n        self.prev_button = tk.Button(root, text=\"<< Prev\", command=self.show_prev_image)\n        self.prev_button.pack(side=tk.LEFT)\n        self.next_button = tk.Button(root, text=\"Next >>\", command=self.show_next_image)\n        self.next_button.pack(side=tk.RIGHT)\n        \n        self.photo = None  # Placeholder for the image display\n        self.update_image(DEFAULT_THRESHOLD)  # Display the default threshold image\n\n    def on_slider_change(self, event):\n        threshold = int(self.threshold_slider.get())\n        self.update_image(threshold)\n\n    def show_prev_image(self):\n        current_value = int(self.threshold_slider.get())\n        new_value = max(self.threshold_slider.cget(\"from\"), current_value - 1)\n        self.threshold_slider.set(new_value)\n        self.update_image(new_value)\n\n    def show_next_image(self):\n        current_value = int(self.threshold_slider.get())\n        new_value = min(self.threshold_slider.cget(\"to\"), current_value + 1)\n        self.threshold_slider.set(new_value)\n        self.update_image(new_value)\n\n    def update_image(self, threshold):\n        # Fetch pre-rendered image if available\n        image = processed_images.get(threshold)\n        if image:\n            self.photo = ImageTk.PhotoImage(image)\n            self.canvas.create_image(0, 0, anchor=\"nw\", image=self.photo)\n            self.root.update()\n        else:\n            print(f\"No pre-rendered image available for threshold: {threshold}\")\n\n# Display the tuning interface\ndef show_tuning_interface(image):\n    root = tk.Tk()\n    root.title(\"Background Removal Tuner\")\n    loading_label = tk.Label(root, text=\"Loading... Please wait\")\n    loading_label.pack()\n    progress_label = tk.Label(root, text=\"Rendering Progress: 0/15000\", font=(\"Arial\", 10))\n    progress_label.pack()\n    tuner_app = BackgroundRemovalTuner(root, image, progress_label)\n    root.after(100, lambda: loading_label.destroy())\n    threading.Thread(target=pre_render_images, args=(image, initial_batch, combinations, progress_label)).start()\n    root.mainloop()\n\n# Capture selected area and show tuning interface\n# Capture selected area and show tuning interface\n# Capture selected area and show tuning interface\ndef capture_selected_area(x1, y1, x2, y2):\n    # Grab the selected screen area\n    image = ImageGrab.grab(bbox=(x1, y1, x2, y2)).convert(\"RGBA\")\n    \n    # Initialize the GUI\n    root = tk.Tk()\n    root.title(\"Background Removal Tuner\")\n    \n    # Create a progress label for tracking rendering progress\n    progress_label = tk.Label(root, text=\"Rendering Progress: 0/15000\")\n    progress_label.pack()\n    \n    # Pass the progress_label to BackgroundRemovalTuner\n    tuner_app = BackgroundRemovalTuner(root, image, progress_label)\n    \n    # Update the GUI and show the initial image as the GUI loads\n    root.update()  \n    \n    # Start pre-rendering in a background thread\n    threading.Thread(target=pre_render_images, args=(image, initial_batch, combinations, progress_label, tuner_app)).start()\n    \n    # Start the GUI main loop\n    root.mainloop()\n\n# Select area on the screen\ndef select_area():\n    root = tk.Tk()\n    root.attributes(\"-fullscreen\", True)\n    root.attributes(\"-alpha\", 0.3)\n    root.config(bg=\"black\")\n    start_x = start_y = end_x = end_y = 0\n    rect = None\n\n    def on_mouse_down(event):\n        nonlocal start_x, start_y, rect\n        start_x, start_y = event.x, event.y\n        if rect:\n            canvas.delete(rect)\n        rect = canvas.create_rectangle(start_x, start_y, start_x, start_y, outline=\"red\", width=2)\n\n    def on_mouse_drag(event):\n        nonlocal rect, end_x, end_y\n        end_x, end_y = event.x, event.y\n        if rect:\n            canvas.delete(rect)\n        rect = canvas.create_rectangle(start_x, start_y, end_x, end_y, outline=\"red\", width=2)\n\n    def on_mouse_up(event):\n        root.quit()\n        root.destroy()\n        capture_selected_area(start_x, start_y, end_x, end_y)\n\n    canvas = tk.Canvas(root, cursor=\"cross\")\n    canvas.pack(fill=\"both\", expand=True)\n    canvas.bind(\"<ButtonPress-1>\", on_mouse_down)\n    canvas.bind(\"<B1-Motion>\", on_mouse_drag)\n    canvas.bind(\"<ButtonRelease-1>\", on_mouse_up)\n    root.mainloop()\n\n# Tray icon setup\ndef on_exit(icon, item):\n    icon.stop()\n    sys.exit()\n\ndef run_tray():\n    icon_image = PilImage.open(\"icon.ico\")\n    icon = pystray.Icon(\"NoBackgroundSnipper\", icon_image, menu=pystray.Menu(item('Exit', on_exit)))\n    icon.run()\n\n# Start tray, pre-render, and set up hotkeys\nif __name__ == \"__main__\":\n    threading.Thread(target=run_tray, daemon=True).start()\n    keyboard.add_hotkey(\"ctrl+alt+s\", select_area)\n    keyboard.add_hotkey(\"ctrl+alt+q\", lambda: sys.exit())\n    print(\"Running in the system tray. Press Ctrl+Alt+S to capture screen selection and remove background. Press Ctrl+Alt+Q to exit.\")\n    keyboard.wait(\"esc\")\n"
        },
        "SelectObjects.py": {
            "methods": [
                "select_objects",
                "update_selected_objects",
                "on_hover",
                "on_click",
                "on_right_click"
            ],
            "code": "import cv2\nimport numpy as np\n\n# Select objects within the image\ndef select_objects(canvas, contours, selected_objects, update_copy_button_state, update_selected_objects):\n    tool_mode = \"select\"\n    canvas.config(cursor=\"arrow\")\n    \n    def on_hover(event):\n        x, y = event.x, event.y\n        for contour in contours:\n            if cv2.pointPolygonTest(contour, (x, y), False) >= 0:\n                canvas.config(cursor=\"hand2\")\n                return\n        canvas.config(cursor=\"arrow\")\n\n    def on_click(event):\n        x, y = event.x, event.y\n        for contour in contours:\n            if cv2.pointPolygonTest(contour, (x, y), False) >= 0:\n                if not any(np.array_equal(contour, selected) for selected in selected_objects):\n                    selected_objects.append(contour)\n                    update_copy_button_state()\n                    update_selected_objects()\n                return\n\n    def on_right_click(event):\n        x, y = event.x, event.y\n        for contour in selected_objects:\n            if cv2.pointPolygonTest(contour, (x, y), False) >= 0:\n                selected_objects = [c for c in selected_objects if not np.array_equal(c, contour)]\n                update_copy_button_state()\n                update_selected_objects()\n                return\n\n    canvas.bind(\"<Motion>\", on_hover)\n    canvas.bind(\"<ButtonPress-1>\", on_click)\n    canvas.bind(\"<ButtonPress-3>\", on_right_click)\n\n# Update selected objects on the canvas\ndef update_selected_objects(open_cv_image, selected_objects, contours, handle_contour_coloring, update_canvas):\n    updated_image = handle_contour_coloring(open_cv_image.copy(), selected_objects, contours)\n    update_canvas(updated_image)\n"
        },
        "Undo.py": {
            "methods": [
                "undo_last_action"
            ],
            "code": "# Undo functionality\ndef undo_last_action(history, update_canvas):\n    if len(history) > 1:\n        history.pop()  # Remove the last action\n        previous_state = history[-1]\n        update_canvas(previous_state)\n"
        },
        "model\\u2net.py": {
            "methods": [
                "_upsample_like",
                "__init__",
                "forward",
                "__init__",
                "forward",
                "__init__",
                "forward",
                "__init__",
                "forward",
                "__init__",
                "forward",
                "__init__",
                "forward",
                "__init__",
                "forward",
                "__init__",
                "forward"
            ],
            "code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass REBNCONV(nn.Module):\n    def __init__(self,in_ch=3,out_ch=3,dirate=1):\n        super(REBNCONV,self).__init__()\n\n        self.conv_s1 = nn.Conv2d(in_ch,out_ch,3,padding=1*dirate,dilation=1*dirate)\n        self.bn_s1 = nn.BatchNorm2d(out_ch)\n        self.relu_s1 = nn.ReLU(inplace=True)\n\n    def forward(self,x):\n\n        hx = x\n        xout = self.relu_s1(self.bn_s1(self.conv_s1(hx)))\n\n        return xout\n\n## upsample tensor 'src' to have the same spatial size with tensor 'tar'\ndef _upsample_like(src,tar):\n\n    src = F.upsample(src,size=tar.shape[2:],mode='bilinear')\n\n    return src\n\n\n### RSU-7 ###\nclass RSU7(nn.Module):#UNet07DRES(nn.Module):\n\n    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n        super(RSU7,self).__init__()\n\n        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n\n        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n        self.pool3 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=1)\n        self.pool4 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.rebnconv5 = REBNCONV(mid_ch,mid_ch,dirate=1)\n        self.pool5 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.rebnconv6 = REBNCONV(mid_ch,mid_ch,dirate=1)\n\n        self.rebnconv7 = REBNCONV(mid_ch,mid_ch,dirate=2)\n\n        self.rebnconv6d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n        self.rebnconv5d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n        self.rebnconv4d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n\n    def forward(self,x):\n\n        hx = x\n        hxin = self.rebnconvin(hx)\n\n        hx1 = self.rebnconv1(hxin)\n        hx = self.pool1(hx1)\n\n        hx2 = self.rebnconv2(hx)\n        hx = self.pool2(hx2)\n\n        hx3 = self.rebnconv3(hx)\n        hx = self.pool3(hx3)\n\n        hx4 = self.rebnconv4(hx)\n        hx = self.pool4(hx4)\n\n        hx5 = self.rebnconv5(hx)\n        hx = self.pool5(hx5)\n\n        hx6 = self.rebnconv6(hx)\n\n        hx7 = self.rebnconv7(hx6)\n\n        hx6d =  self.rebnconv6d(torch.cat((hx7,hx6),1))\n        hx6dup = _upsample_like(hx6d,hx5)\n\n        hx5d =  self.rebnconv5d(torch.cat((hx6dup,hx5),1))\n        hx5dup = _upsample_like(hx5d,hx4)\n\n        hx4d = self.rebnconv4d(torch.cat((hx5dup,hx4),1))\n        hx4dup = _upsample_like(hx4d,hx3)\n\n        hx3d = self.rebnconv3d(torch.cat((hx4dup,hx3),1))\n        hx3dup = _upsample_like(hx3d,hx2)\n\n        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n        hx2dup = _upsample_like(hx2d,hx1)\n\n        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n\n        return hx1d + hxin\n\n### RSU-6 ###\nclass RSU6(nn.Module):#UNet06DRES(nn.Module):\n\n    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n        super(RSU6,self).__init__()\n\n        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n\n        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n        self.pool3 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=1)\n        self.pool4 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.rebnconv5 = REBNCONV(mid_ch,mid_ch,dirate=1)\n\n        self.rebnconv6 = REBNCONV(mid_ch,mid_ch,dirate=2)\n\n        self.rebnconv5d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n        self.rebnconv4d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n\n    def forward(self,x):\n\n        hx = x\n\n        hxin = self.rebnconvin(hx)\n\n        hx1 = self.rebnconv1(hxin)\n        hx = self.pool1(hx1)\n\n        hx2 = self.rebnconv2(hx)\n        hx = self.pool2(hx2)\n\n        hx3 = self.rebnconv3(hx)\n        hx = self.pool3(hx3)\n\n        hx4 = self.rebnconv4(hx)\n        hx = self.pool4(hx4)\n\n        hx5 = self.rebnconv5(hx)\n\n        hx6 = self.rebnconv6(hx5)\n\n\n        hx5d =  self.rebnconv5d(torch.cat((hx6,hx5),1))\n        hx5dup = _upsample_like(hx5d,hx4)\n\n        hx4d = self.rebnconv4d(torch.cat((hx5dup,hx4),1))\n        hx4dup = _upsample_like(hx4d,hx3)\n\n        hx3d = self.rebnconv3d(torch.cat((hx4dup,hx3),1))\n        hx3dup = _upsample_like(hx3d,hx2)\n\n        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n        hx2dup = _upsample_like(hx2d,hx1)\n\n        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n\n        return hx1d + hxin\n\n### RSU-5 ###\nclass RSU5(nn.Module):#UNet05DRES(nn.Module):\n\n    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n        super(RSU5,self).__init__()\n\n        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n\n        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n        self.pool3 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=1)\n\n        self.rebnconv5 = REBNCONV(mid_ch,mid_ch,dirate=2)\n\n        self.rebnconv4d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n\n    def forward(self,x):\n\n        hx = x\n\n        hxin = self.rebnconvin(hx)\n\n        hx1 = self.rebnconv1(hxin)\n        hx = self.pool1(hx1)\n\n        hx2 = self.rebnconv2(hx)\n        hx = self.pool2(hx2)\n\n        hx3 = self.rebnconv3(hx)\n        hx = self.pool3(hx3)\n\n        hx4 = self.rebnconv4(hx)\n\n        hx5 = self.rebnconv5(hx4)\n\n        hx4d = self.rebnconv4d(torch.cat((hx5,hx4),1))\n        hx4dup = _upsample_like(hx4d,hx3)\n\n        hx3d = self.rebnconv3d(torch.cat((hx4dup,hx3),1))\n        hx3dup = _upsample_like(hx3d,hx2)\n\n        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n        hx2dup = _upsample_like(hx2d,hx1)\n\n        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n\n        return hx1d + hxin\n\n### RSU-4 ###\nclass RSU4(nn.Module):#UNet04DRES(nn.Module):\n\n    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n        super(RSU4,self).__init__()\n\n        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n\n        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n        self.pool1 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=1)\n        self.pool2 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=1)\n\n        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=2)\n\n        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=1)\n        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n\n    def forward(self,x):\n\n        hx = x\n\n        hxin = self.rebnconvin(hx)\n\n        hx1 = self.rebnconv1(hxin)\n        hx = self.pool1(hx1)\n\n        hx2 = self.rebnconv2(hx)\n        hx = self.pool2(hx2)\n\n        hx3 = self.rebnconv3(hx)\n\n        hx4 = self.rebnconv4(hx3)\n\n        hx3d = self.rebnconv3d(torch.cat((hx4,hx3),1))\n        hx3dup = _upsample_like(hx3d,hx2)\n\n        hx2d = self.rebnconv2d(torch.cat((hx3dup,hx2),1))\n        hx2dup = _upsample_like(hx2d,hx1)\n\n        hx1d = self.rebnconv1d(torch.cat((hx2dup,hx1),1))\n\n        return hx1d + hxin\n\n### RSU-4F ###\nclass RSU4F(nn.Module):#UNet04FRES(nn.Module):\n\n    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n        super(RSU4F,self).__init__()\n\n        self.rebnconvin = REBNCONV(in_ch,out_ch,dirate=1)\n\n        self.rebnconv1 = REBNCONV(out_ch,mid_ch,dirate=1)\n        self.rebnconv2 = REBNCONV(mid_ch,mid_ch,dirate=2)\n        self.rebnconv3 = REBNCONV(mid_ch,mid_ch,dirate=4)\n\n        self.rebnconv4 = REBNCONV(mid_ch,mid_ch,dirate=8)\n\n        self.rebnconv3d = REBNCONV(mid_ch*2,mid_ch,dirate=4)\n        self.rebnconv2d = REBNCONV(mid_ch*2,mid_ch,dirate=2)\n        self.rebnconv1d = REBNCONV(mid_ch*2,out_ch,dirate=1)\n\n    def forward(self,x):\n\n        hx = x\n\n        hxin = self.rebnconvin(hx)\n\n        hx1 = self.rebnconv1(hxin)\n        hx2 = self.rebnconv2(hx1)\n        hx3 = self.rebnconv3(hx2)\n\n        hx4 = self.rebnconv4(hx3)\n\n        hx3d = self.rebnconv3d(torch.cat((hx4,hx3),1))\n        hx2d = self.rebnconv2d(torch.cat((hx3d,hx2),1))\n        hx1d = self.rebnconv1d(torch.cat((hx2d,hx1),1))\n\n        return hx1d + hxin\n\n\n##### U^2-Net ####\nclass U2NET(nn.Module):\n\n    def __init__(self,in_ch=3,out_ch=1):\n        super(U2NET,self).__init__()\n\n        self.stage1 = RSU7(in_ch,32,64)\n        self.pool12 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.stage2 = RSU6(64,32,128)\n        self.pool23 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.stage3 = RSU5(128,64,256)\n        self.pool34 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.stage4 = RSU4(256,128,512)\n        self.pool45 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.stage5 = RSU4F(512,256,512)\n        self.pool56 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.stage6 = RSU4F(512,256,512)\n\n        # decoder\n        self.stage5d = RSU4F(1024,256,512)\n        self.stage4d = RSU4(1024,128,256)\n        self.stage3d = RSU5(512,64,128)\n        self.stage2d = RSU6(256,32,64)\n        self.stage1d = RSU7(128,16,64)\n\n        self.side1 = nn.Conv2d(64,out_ch,3,padding=1)\n        self.side2 = nn.Conv2d(64,out_ch,3,padding=1)\n        self.side3 = nn.Conv2d(128,out_ch,3,padding=1)\n        self.side4 = nn.Conv2d(256,out_ch,3,padding=1)\n        self.side5 = nn.Conv2d(512,out_ch,3,padding=1)\n        self.side6 = nn.Conv2d(512,out_ch,3,padding=1)\n\n        self.outconv = nn.Conv2d(6*out_ch,out_ch,1)\n\n    def forward(self,x):\n\n        hx = x\n\n        #stage 1\n        hx1 = self.stage1(hx)\n        hx = self.pool12(hx1)\n\n        #stage 2\n        hx2 = self.stage2(hx)\n        hx = self.pool23(hx2)\n\n        #stage 3\n        hx3 = self.stage3(hx)\n        hx = self.pool34(hx3)\n\n        #stage 4\n        hx4 = self.stage4(hx)\n        hx = self.pool45(hx4)\n\n        #stage 5\n        hx5 = self.stage5(hx)\n        hx = self.pool56(hx5)\n\n        #stage 6\n        hx6 = self.stage6(hx)\n        hx6up = _upsample_like(hx6,hx5)\n\n        #-------------------- decoder --------------------\n        hx5d = self.stage5d(torch.cat((hx6up,hx5),1))\n        hx5dup = _upsample_like(hx5d,hx4)\n\n        hx4d = self.stage4d(torch.cat((hx5dup,hx4),1))\n        hx4dup = _upsample_like(hx4d,hx3)\n\n        hx3d = self.stage3d(torch.cat((hx4dup,hx3),1))\n        hx3dup = _upsample_like(hx3d,hx2)\n\n        hx2d = self.stage2d(torch.cat((hx3dup,hx2),1))\n        hx2dup = _upsample_like(hx2d,hx1)\n\n        hx1d = self.stage1d(torch.cat((hx2dup,hx1),1))\n\n\n        #side output\n        d1 = self.side1(hx1d)\n\n        d2 = self.side2(hx2d)\n        d2 = _upsample_like(d2,d1)\n\n        d3 = self.side3(hx3d)\n        d3 = _upsample_like(d3,d1)\n\n        d4 = self.side4(hx4d)\n        d4 = _upsample_like(d4,d1)\n\n        d5 = self.side5(hx5d)\n        d5 = _upsample_like(d5,d1)\n\n        d6 = self.side6(hx6)\n        d6 = _upsample_like(d6,d1)\n\n        d0 = self.outconv(torch.cat((d1,d2,d3,d4,d5,d6),1))\n\n        return F.sigmoid(d0), F.sigmoid(d1), F.sigmoid(d2), F.sigmoid(d3), F.sigmoid(d4), F.sigmoid(d5), F.sigmoid(d6)\n\n### U^2-Net small ###\nclass U2NETP(nn.Module):\n\n    def __init__(self,in_ch=3,out_ch=1):\n        super(U2NETP,self).__init__()\n\n        self.stage1 = RSU7(in_ch,16,64)\n        self.pool12 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.stage2 = RSU6(64,16,64)\n        self.pool23 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.stage3 = RSU5(64,16,64)\n        self.pool34 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.stage4 = RSU4(64,16,64)\n        self.pool45 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.stage5 = RSU4F(64,16,64)\n        self.pool56 = nn.MaxPool2d(2,stride=2,ceil_mode=True)\n\n        self.stage6 = RSU4F(64,16,64)\n\n        # decoder\n        self.stage5d = RSU4F(128,16,64)\n        self.stage4d = RSU4(128,16,64)\n        self.stage3d = RSU5(128,16,64)\n        self.stage2d = RSU6(128,16,64)\n        self.stage1d = RSU7(128,16,64)\n\n        self.side1 = nn.Conv2d(64,out_ch,3,padding=1)\n        self.side2 = nn.Conv2d(64,out_ch,3,padding=1)\n        self.side3 = nn.Conv2d(64,out_ch,3,padding=1)\n        self.side4 = nn.Conv2d(64,out_ch,3,padding=1)\n        self.side5 = nn.Conv2d(64,out_ch,3,padding=1)\n        self.side6 = nn.Conv2d(64,out_ch,3,padding=1)\n\n        self.outconv = nn.Conv2d(6*out_ch,out_ch,1)\n\n    def forward(self,x):\n\n        hx = x\n\n        #stage 1\n        hx1 = self.stage1(hx)\n        hx = self.pool12(hx1)\n\n        #stage 2\n        hx2 = self.stage2(hx)\n        hx = self.pool23(hx2)\n\n        #stage 3\n        hx3 = self.stage3(hx)\n        hx = self.pool34(hx3)\n\n        #stage 4\n        hx4 = self.stage4(hx)\n        hx = self.pool45(hx4)\n\n        #stage 5\n        hx5 = self.stage5(hx)\n        hx = self.pool56(hx5)\n\n        #stage 6\n        hx6 = self.stage6(hx)\n        hx6up = _upsample_like(hx6,hx5)\n\n        #decoder\n        hx5d = self.stage5d(torch.cat((hx6up,hx5),1))\n        hx5dup = _upsample_like(hx5d,hx4)\n\n        hx4d = self.stage4d(torch.cat((hx5dup,hx4),1))\n        hx4dup = _upsample_like(hx4d,hx3)\n\n        hx3d = self.stage3d(torch.cat((hx4dup,hx3),1))\n        hx3dup = _upsample_like(hx3d,hx2)\n\n        hx2d = self.stage2d(torch.cat((hx3dup,hx2),1))\n        hx2dup = _upsample_like(hx2d,hx1)\n\n        hx1d = self.stage1d(torch.cat((hx2dup,hx1),1))\n\n\n        #side output\n        d1 = self.side1(hx1d)\n\n        d2 = self.side2(hx2d)\n        d2 = _upsample_like(d2,d1)\n\n        d3 = self.side3(hx3d)\n        d3 = _upsample_like(d3,d1)\n\n        d4 = self.side4(hx4d)\n        d4 = _upsample_like(d4,d1)\n\n        d5 = self.side5(hx5d)\n        d5 = _upsample_like(d5,d1)\n\n        d6 = self.side6(hx6)\n        d6 = _upsample_like(d6,d1)\n\n        d0 = self.outconv(torch.cat((d1,d2,d3,d4,d5,d6),1))\n\n        return F.sigmoid(d0), F.sigmoid(d1), F.sigmoid(d2), F.sigmoid(d3), F.sigmoid(d4), F.sigmoid(d5), F.sigmoid(d6)\n"
        }
    }
}